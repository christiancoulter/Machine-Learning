{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZoXm_MxHnAumCnYBu4AZ0yXn4MGYyVKw","timestamp":1703129218768},{"file_id":"12RAZIizWGhbYy1heAGwjSlx5QdbP3LCi","timestamp":1583988510449},{"file_id":"1d7R1v7Ie0EYkwSBwv8_hG4ad1fWmXmil","timestamp":1583698890415},{"file_id":"1HKzoP0RV5sS4bq29P8wSL8TiesrF4y3J","timestamp":1582783503697},{"file_id":"1XaQBpkbanCXFxxJ1ghT9e4CqFstOCF8G","timestamp":1582585052121},{"file_id":"1bUVTGtdPQASsA0heGjrU-N3WmBWuB6u_","timestamp":1582497019436},{"file_id":"1rGXFqRqm039V8CFbgHhJIelkvjMtjccM","timestamp":1581473139504},{"file_id":"1LvZxCmUnjHLiPXq5jdvyQionnTMMYItf","timestamp":1581323022958}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8iwaee_T-Urj"},"source":["# ASSIGNMENT 5 - INTRO TO MACHINE LEARNING | Decision Tree, Bagging, Random Forest and Boosting\n","\n","\n","> **FULL MARKS =100**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GhorwbNcOblB"},"source":["\n","\n","1.2. Leave-One-Out Cross Validation(LOOCV) | SCORE :\n"]},{"cell_type":"markdown","metadata":{"id":"IVKgB-iQ-nYY"},"source":["**Note:** To submit the assignment, please follow the same steps as in assignments 1-4.\n","\n","In this assignment we will use things we have learned from previous exercises. You will not be given instructions on how to load data, plot data, standardize/normalize data, how to write functions and many more. You will be given instructions on what you will be doing. **SO PLEASE START THIS ASSIGNMENT AS EARLY AS POSSIBLE**\n","\n","1. **Decision Tree with kfold cv| SCORE : 25**\n","> https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n","  \n","  **1.1 Regression**\n","      \n","    References\n","    > https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor\n","\n","  **1.2 Classification**\n","      \n","    References\n","    > https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n","\n","\n","2. **Decision Tree with bagging | SCORE : 25**\n","  \n","  **2.1 Regression**\n","      \n","    References\n","    > https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor\n","\n","  **2.2 Classification**\n","      \n","    References\n","    > https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n","\n","3. **Random Forest | SCORE : 25**\n","  \n","  **3.1 Regression**\n","      \n","    References\n","    > https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n","\n","  **3.2 Classification**\n","      \n","    References\n","    > https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n","\n","4. **Boosting | SCORE : 25**\n","  \n","  **4.1 Regression**\n","      \n","    References\n","    > https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\n","\n","  **4.2 Classification**\n","      \n","    References\n","    > https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n"]},{"cell_type":"code","metadata":{"id":"Zug9NBE22fvi","outputId":"3f3c51e2-7e95-47f2-88d6-4996e360f128","executionInfo":{"status":"ok","timestamp":1584037742078,"user_tz":300,"elapsed":354,"user":{"displayName":"Keshav Bhandari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC-uDKu3A2mC5yHspIBmA_YWrlUhK0mlUd_RtUUA=s64","userId":"02531507800239803413"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Required Dataset\n","# For classification\n","from sklearn.datasets import load_breast_cancer\n","# For regression\n","from sklearn.datasets import load_diabetes\n","\n","# In the following exercises you will use the\n","# breast_cancer, and diabetes datasets for classification and regression problems respectively.\n","# Use your experience from previous exercises on how to use sklearn model, load data and do visualization\n","# You will not be given points for preparing the dataset\n","# So We are going to do this for you\n","# You are welcome to load data set way you want\n","# Please try to research about following the datasets, load_breast_cancer, load_diabetes data set\n","\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","regx, regy = load_diabetes(return_X_y=True)\n","regX = preprocessing.scale(regx)\n","regXtrain, regXtest, regYtrain, regYtest = train_test_split(regX, regy, test_size = 0.2)\n","\n","print(f\"Regression data : diabetes data\")\n","print(f\"xtrainShape : {regXtrain.shape}, ytrainShape : {regYtrain.shape}, xtestShape : {regXtest.shape}, ytestShape : {regYtest.shape}\")\n","\n","clsx, clsy = load_breast_cancer(return_X_y=True)\n","clsX = preprocessing.scale(clsx)\n","clsXtrain, clsXtest, clsYtrain, clsYtest = train_test_split(clsX, clsy, test_size = 0.2)\n","print(f\"Classification data : breast cancer data\")\n","print(f\"xtrainShape : {clsXtrain.shape}, ytrainShape : {clsYtrain.shape}, xtestShape : {clsXtest.shape}, ytestShape : {clsYtest.shape}, NumClasses = {np.unique(clsy)}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Regression data : diabetes data\n","xtrainShape : (353, 10), ytrainShape : (353,), xtestShape : (89, 10), ytestShape : (89,)\n","Classification data : breast cancer data\n","xtrainShape : (455, 30), ytrainShape : (455,), xtestShape : (114, 30), ytestShape : (114,), NumClasses = [0 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NsUM8-i_KhK1"},"source":["### 1. Decision Tree with kfold cv\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vyOkwgrKML85"},"source":["***EXERCISE NO. 1***\n","\n","  > **Task-1 : Regression | Score :12.5**"]},{"cell_type":"code","metadata":{"id":"KpXjE-MW9w2-"},"source":["# Use the bosting diabetes dataset to achieve the following task\n","# You are welcome to visit all the examples in the given references\n","# https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py\n","# One in above is a close example\n","\n","# Achieve following task\n","\n","# Create a decision tree regressor model, use max_depth size = 1,2,5,100\n","# Fit model. You will have 4 different models for different depth sizes\n","# Plot a similar plot as in the link given above\n","# Describe your plot\n","\n","\n","# Finally pick the best max_depth you got(you should know how to get the score)\n","# Use this max_depth, and use cross_val_score and fit your model with k = 10 fold size\n","# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n","# Plot scores in y axis and k in x axis\n","# Calculate average scores in kfold\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k6GbZ91B57Em"},"source":["***EXERCISE NO. 1***\n","\n","  > **Task-2 :Classification | Score :12.5**"]},{"cell_type":"code","metadata":{"id":"H11Lq0_h57Ep"},"source":["# https://scikit-learn.org/stable/auto_examples/tree/plot_iris_dtc.html#sphx-glr-auto-examples-tree-plot-iris-dtc-py\n","# Perform similar experiment like above in breast_cancer data\n","\n","\n","# Use cross_val_score and fit your model with k = 10 fold size\n","# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n","# Plot scores in y axis and k in x axis\n","# Calculate average scores in kfold\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lRbooEUo6Iie"},"source":["### 2. Decision Tree with bagging\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RvR7FYAX6Iig"},"source":["***EXERCISE NO. 2***\n","\n","  > **Task-1 : Regression | Score :12.5**"]},{"cell_type":"code","metadata":{"id":"Nex0l0_p6Iig"},"source":["# https://scikit-learn.org/stable/auto_examples/ensemble/plot_bias_variance.html#sphx-glr-auto-examples-ensemble-plot-bias-variance-py\n","\n","# Perform similar experiment like above for diabetes dataset\n","\n","# Explain your data visualization\n","\n","# Compare this bagging approach with kfold cross validation approach we did in 1.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dEKCBljl6Iik"},"source":["***EXERCISE NO. 2***\n","\n","  > **Task-2 :Classification | Score :12.5**"]},{"cell_type":"code","metadata":{"id":"TmPZ3PFj6Iik"},"source":["# Study how bagging classifier is used from below\n","# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n","# Now use visualization as you did in exerciseno1. task2\n","# Explain your visualization\n","\n","# Compare this approach wtih kfold cross validation approach we did in 1.2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UxROm1L86Nva"},"source":["### 3. Random Forest\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1kUINUY66Nvb"},"source":["***EXERCISE NO. 3***\n","\n","  > **Task-1 : Regression | Score :12.5**"]},{"cell_type":"code","metadata":{"id":"QpJkoFQP6Nvc"},"source":["# Study following example\n","# https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_regressor.html#sphx-glr-auto-examples-ensemble-plot-voting-regressor-py\n","# Do similar experiment on diabetes data\n","# Now explain your visualization\n","\n","# How do you compare random forest regression with decision tree regression?\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lTCmM5U76Nve"},"source":["***EXERCISE NO. 3***\n","\n","  > **Task-2 :Classification | Score :12.5**"]},{"cell_type":"code","metadata":{"id":"UylxMC2d6Nvf"},"source":["# Study following example\n","# https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_iris.html#sphx-glr-auto-examples-ensemble-plot-forest-iris-py\n","# Reproduce above experiment for breast_cancer data\n","\n","# Explain your visualization.\n","\n","# How do you compare this approach with decision tree based approach?"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_8gEgGyO6fkQ"},"source":["### 4. Boosting with Gradient Boosting\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TnSoxZci6fkT"},"source":["***EXERCISE NO. 4***\n","\n","  > **Task-1 : Regression | Score :12.5**"]},{"cell_type":"code","metadata":{"id":"FoujQuzP6fkT"},"source":["# https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py\n","# Study above example\n","# Try to reproduce this experiment with diabetes data\n","\n","# Create similar visualization for max_depth = 1,5,10,100\n","\n","# Explain visualization.\n","\n","\n","# How does boosting help your regressor model??\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPcDrCYU6fkY"},"source":["***EXERCISE NO. 4***\n","\n","  > **Task-2 :Classification | Score :12.5**"]},{"cell_type":"code","metadata":{"id":"rw10jNkp6fkZ"},"source":["# https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_oob.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-oob-py\n","# Study above example\n","# Try to reproduce this experiment with cancer data\n","\n","# Create similar visualization for max_depth = 1,5,10,100,1000\n","\n","# Explain your visualization.\n","\n","\n","# How does boosting help your classification model??\n","\n"],"execution_count":null,"outputs":[]}]}
